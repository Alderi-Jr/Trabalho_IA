# ğŸ§Ÿâ€â™‚ï¸ Apocalypse RL â€“ Q-Learning com Mapas AleatÃ³rios

Este projeto implementa um ambiente pÃ³s-apocalipse utilizando **Gym**, **PyGame** e **Q-Learning**, onde um agente deve sobreviver, coletar suprimentos, evitar zumbis e chegar atÃ© a zona segura.  
O ambiente Ã© totalmente aleatÃ³rio a cada execuÃ§Ã£o, e o treinamento Ã© exibido visualmente via HUD em tempo real.

> Baseado nos arquivos reais do projeto:
> - `environment.py`
> - `qlearning.py`
> - `main.py`

---

## ğŸ“Œ Funcionalidades Principais

- âœ”ï¸ GeraÃ§Ã£o **totalmente aleatÃ³ria** de mapas 10Ã—10  
- âœ”ï¸ Paredes, rochas, suprimentos, zumbis e safe zone distribuÃ­dos **sem sobreposiÃ§Ã£o**  
- âœ”ï¸ Ambiente compatÃ­vel com **Gym**  
- âœ”ï¸ RenderizaÃ§Ã£o completa via **PyGame** com HUD lateral  
- âœ”ï¸ Agente aprende via **Q-Learning**  
- âœ”ï¸ Replay do melhor episÃ³dio encontrado  
- âœ”ï¸ Controles interativos:
  - **R** â†’ Reproduzir melhor episÃ³dio  
  - **N** â†’ Novo mapa + treinar  
  - **SPACE** â†’ AvanÃ§ar um passo  
  - **ESC** â†’ Sair  

---

## ğŸ—ºï¸ Ambiente â€“ `environment.py`

O ambiente (`ApocalypseEnvironment`) funciona com:

### ğŸ”¹ ObservaÃ§Ã£o
Tupla com 5 valores:  
`(x, y, f0, f1, f2)`  
Onde `f0-f2` sÃ£o flags binÃ¡rias indicando suprimentos coletados.

### ğŸ”¹ AÃ§Ãµes
| ID | Significado |
|----|-------------|
| 0  | â†‘           |
| 1  | â†’           |
| 2  | â†“           |
| 3  | â†           |

### ğŸ”¹ Recompensas
| SituaÃ§Ã£o                          | Recompensa |
|----------------------------------|------------|
| Movimento normal                 | -0.2       |
| Coletar suprimento               | +30        |
| Safe zone sem suprimentos        | -20        |
| Safe zone com todos suprimentos  | +120       |
| Encontrar zumbi                  | -15 (terminal) |

### ğŸ”¹ RenderizaÃ§Ã£o PyGame
- Tabuleiro em grid 10Ã—10  
- Sprites: chÃ£o, parede, rocha, suprimento, zumbi, agente e safe zone  
- HUD com:
  - Passos
  - Recompensa total
  - EpisÃ³dio atual
  - Melhor recompensa
  - Estado dos suprimentos coletados
  - Ãšltima aÃ§Ã£o

---

## ğŸ¤– Q-Learning â€“ `qlearning.py`

ImplementaÃ§Ã£o de Q-Learning com:

### ğŸ”¹ Estrutura da Q-table

Q[grid_x][grid_y][f0][f1][f2][action]

## ğŸ”¹ ParÃ¢metros principais
- `learning_rate = 0.1`
- `discount_factor = 0.93`
- `exploration_rate` com decaimento automÃ¡tico

### ğŸ”¹ Armazenamento do melhor episÃ³dio REAL
O cÃ³digo salva:

- Melhor recompensa jÃ¡ obtida
- SequÃªncia REAL de aÃ§Ãµes do melhor episÃ³dio â†’ `best_actions`

### ğŸ”¹ CritÃ©rios de parada
- Recompensa â‰¥ 205  
- Ou "paciÃªncia" de 150 episÃ³dios sem melhora

---

## ğŸ¯ Loop Principal â€“ `main.py`

O arquivo `main.py` faz:

### âœ”ï¸ Treinamento visual
Chamando `train_with_hud()` que vai atualizando o PyGame durante cada episÃ³dio.

### âœ”ï¸ Salvamento automÃ¡tico
ApÃ³s o treinamento:
q_table_stateflags.pkl
best_actions.pkl


### âœ”ï¸ Replay
Executa o melhor caminho encontrado:
- Mostrado passo a passo no PyGame
- Respeita teclas R / N / SPACE / ESC

### âœ”ï¸ Novo mapa completo
Tecla **N** gera outro mapa totalmente aleatÃ³rio e reinicia treinamento.

---

## ğŸ§± Estrutura do Projeto

/
â”œâ”€â”€ environment.py
â”œâ”€â”€ qlearning.py
â”œâ”€â”€ main.py
â”œâ”€â”€ assets/
â”‚ â”œâ”€â”€ agent.png
â”‚ â”œâ”€â”€ zombie.png
â”‚ â”œâ”€â”€ floor.png
â”‚ â”œâ”€â”€ rock.png
â”‚ â”œâ”€â”€ wall.png
â”‚ â”œâ”€â”€ supply.png
â”‚ â””â”€â”€ safe.png
â””â”€â”€ README.md


---

## â–¶ï¸ Como Executar

### 1ï¸âƒ£ Instalar dependÃªncias
```bash
pip install pygame gym numpy
python main.py


ğŸ§ª Comportamento Esperado

O agente nasce no canto superior esquerdo

Coleta suprimentos espalhados

Desvia de paredes, rochas e zumbis

Vai atÃ© a safe zone

HUD mostra toda a evoluÃ§Ã£o do treinamento

Replay permite visualizar o melhor trajeto real

ğŸš€ Melhorias Futuras

Usar DQN (Deep Q-Learning)

Criar mapas conectados via BFS/DFS

Inserir mÃºltiplos agentes

Inserir diferentes tipos de inimigos

Balancear recompensas

GeraÃ§Ã£o procedural mais inteligente
